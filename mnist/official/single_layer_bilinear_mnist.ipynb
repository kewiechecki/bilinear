{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC1FbXRr8Bve"
      },
      "source": [
        "# MNIST | Single Layer Bilinear Model\n",
        "This notebook trains the model and generates the figures for the paper \"Weight-based Decomposition: A Case for Bilinear MLPs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMwuV3PaAtGB"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrTGmVoTE2VG"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjtmA8N8DTwI",
        "outputId": "381f5983-06e7-4084-cdf6-1baa8903255e"
      },
      "outputs": [],
      "source": [
        "!pip install einops\n",
        "!pip install jaxtyping\n",
        "!git clone https://github.com/tdooms/bilinear-interp.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8XjarZTDd6q",
        "outputId": "e240fffc-6250-4146-cdfd-7acfb8183f00"
      },
      "outputs": [],
      "source": [
        "%cd /content/bilinear-interp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHNi-SI0GShV"
      },
      "outputs": [],
      "source": [
        "# !git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMi-KWrPDq10"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import itertools\n",
        "import einops\n",
        "from collections import defaultdict\n",
        "import copy\n",
        "\n",
        "from mnist.model import *\n",
        "from mnist.utils import *\n",
        "from mnist.plotting import *\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiLi8oaKE7k3"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rulD034sImA",
        "outputId": "6aca9910-9f50-4b14-97ca-0508b1edd584"
      },
      "outputs": [],
      "source": [
        "# Import MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYnbDIMo0W6M"
      },
      "outputs": [],
      "source": [
        "# Data loader\n",
        "batch_size = 100\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycAsxmrG0ala",
        "outputId": "2d1760ad-36d4-4da3-9786-04135fd8eb81"
      },
      "outputs": [],
      "source": [
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='binary')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXx-e3J-FTpW"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SFTwrZOICPi",
        "outputId": "45210806-dd6b-47a9-8361-e190913daacb"
      },
      "outputs": [],
      "source": [
        "cfg = MnistConfig()\n",
        "cfg.random_seed = 0\n",
        "cfg.n_layers = 1\n",
        "cfg.d_hidden = 300\n",
        "cfg.num_epochs = 2 + 10 + 10\n",
        "cfg.lr = 0.001\n",
        "cfg.lr_decay = 0.5\n",
        "cfg.lr_decay_step = 2\n",
        "cfg.weight_decay = 0.5\n",
        "cfg.rms_norm = False\n",
        "cfg.bias = False\n",
        "cfg.noise_sparse = 0\n",
        "cfg.noise_dense = 0.33\n",
        "cfg.layer_noise = 0.33\n",
        "cfg.logit_bias = False\n",
        "\n",
        "model = MnistModel(cfg).to(\"cuda\")\n",
        "\n",
        "#Define optimizer and scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "linearLR = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1, total_iters = 2)\n",
        "stepLR = torch.optim.lr_scheduler.StepLR(optimizer, step_size=cfg.lr_decay_step, gamma=cfg.lr_decay)\n",
        "constLR = torch.optim.lr_scheduler.ConstantLR(optimizer, factor = cfg.lr_decay**(10/cfg.lr_decay_step), total_iters = 1000)\n",
        "scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[linearLR, stepLR, constLR], milestones=[2, 13])\n",
        "\n",
        "model.train(train_loader, test_loader, optimizer = optimizer, scheduler = scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMDtQg-drTSM"
      },
      "source": [
        "# Eigendecomposition\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E42SAWu5vDSX"
      },
      "source": [
        "## Eigenvectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zw93PHlrjwz",
        "outputId": "688d05c4-701e-4289-d04d-792d8aad17db"
      },
      "outputs": [],
      "source": [
        "W = model.layers[0].linear1.weight.to(\"cpu\").detach()\n",
        "V = model.layers[0].linear2.weight.to(\"cpu\").detach()\n",
        "W_out = model.linear_out.weight.to(\"cpu\").detach()\n",
        "W_in = model.linear_in.weight.to(\"cpu\").detach()\n",
        "\n",
        "B = einops.einsum(W_out, W, V, \"class h, h in1, h in2 -> class in1 in2\")\n",
        "B_proj = 0.5 * B + 0.5 * B.transpose(-2,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UZnFBX0vxVdI",
        "outputId": "a61be343-9d9b-4b9f-b4d7-8034c3b9d8ce"
      },
      "outputs": [],
      "source": [
        "logits = torch.eye(B_proj.shape[0], B_proj.shape[0])\n",
        "eig_plotter = EigenvectorPlotter(B_proj, logits, dataset=train_dataset, Embed = W_in)\n",
        "\n",
        "for i in range(10):\n",
        "    eig_plotter.plot_component(i, suptitle=f\"Digit: {i}\", vmax=0.25,\n",
        "                               classes = range(10), topk_eigs = 3, sort='activations')\n",
        "\n",
        "# plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF3tBBX755SP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLPrN1Y91TJw"
      },
      "outputs": [],
      "source": [
        "# save figures\n",
        "file_pre = f'/content/drive/MyDrive/AI Safety/Bilinear Features/Noise Regulation/noise_reg_noise_only_digit_'\n",
        "logits = torch.eye(B_proj.shape[0], B_proj.shape[0])\n",
        "eig_plotter = EigenvectorPlotter(B_proj, logits, dataset=train_dataset, Embed = W_in)\n",
        "\n",
        "for i in range(10):\n",
        "    eig_plotter.plot_component(i, suptitle=f\"Digit: {i}\", vmax=0.25,\n",
        "                               classes = range(10), topk_eigs = 3, sort='activations',\n",
        "                               filename = file_pre+str(i)+'.png')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GINr2ZydFBq8"
      },
      "source": [
        "## Activation Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPD7S0iGE-oS"
      },
      "outputs": [],
      "source": [
        "class_idx = 3\n",
        "\n",
        "Q = B_proj[class_idx]\n",
        "eigvals, eigvecs = torch.linalg.eigh(Q)\n",
        "mask = eigvals > 0.01\n",
        "eigvals = eigvals[mask]\n",
        "eigvecs = eigvecs[:,mask]\n",
        "eigvecs = W_in.T @ eigvecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMtToKfTFMqo"
      },
      "outputs": [],
      "source": [
        "dataset = train_dataset\n",
        "img_size = (28,28)\n",
        "\n",
        "images = dataset.data.reshape(-1, img_size[0]*img_size[1])/255\n",
        "labels = dataset.targets\n",
        "# mask = dataset.targets == class_idx\n",
        "# images = images[mask]\n",
        "sims = images @ eigvecs\n",
        "acts = eigvals * (sims)**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "V9AbURgsFSYk",
        "outputId": "bf621601-abfc-4746-fef0-8c561c4f607b"
      },
      "outputs": [],
      "source": [
        "eig_idx = -3\n",
        "\n",
        "plt.figure(figsize=(8,3),dpi=150, layout='compressed')\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(eigvecs[:,eig_idx].reshape(img_size), cmap='RdBu', vmin=-0.25, vmax=0.25)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('Eigenvector')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.hist(sims[:,eig_idx],100);\n",
        "plt.xlabel('Dot Product')\n",
        "plt.ylabel('Count')\n",
        "plt.yscale('log')\n",
        "plt.xlim(-15,15)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(acts[:,eig_idx],100);\n",
        "plt.xlabel('Activation')\n",
        "plt.ylabel('Count')\n",
        "plt.yscale('log')\n",
        "# plt.xlim(-15,15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "arYs8G9-d1z-",
        "outputId": "20969774-acde-43d2-a762-fd52da7367bf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,3),dpi=150, layout='compressed')\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(eigvecs[:,eig_idx].reshape(img_size), cmap='RdBu', vmin=-0.25, vmax=0.25)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('Eigenvector')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "for digit in range(10):\n",
        "    mask = labels==digit\n",
        "    plt.hist(sims[mask,eig_idx],100, alpha=0.3, label=digit);\n",
        "plt.xlabel('Dot Product')\n",
        "plt.ylabel('Count')\n",
        "plt.yscale('log')\n",
        "plt.xlim(-15,15)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "for digit in range(10):\n",
        "    mask = labels==digit\n",
        "    plt.hist(acts[mask,eig_idx],100, alpha=0.3, label=digit);\n",
        "plt.xlabel('Activation')\n",
        "plt.ylabel('Count')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "# plt.xlim(-15,15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqoTVXMUiihp"
      },
      "outputs": [],
      "source": [
        "dataset = train_dataset\n",
        "img_size = (28,28)\n",
        "images = dataset.data.reshape(-1, img_size[0]*img_size[1])/255\n",
        "images = images.cuda()\n",
        "\n",
        "noise = model.cfg.noise_dense * torch.randn_like(images)\n",
        "_ = model.forward(images.mean(dim=0, keepdim=True) + noise, inference=False)\n",
        "mlp_inputs_noisy = model.layers[0].input\n",
        "\n",
        "_ = model.forward(images, inference=True)\n",
        "mlp_inputs = model.layers[0].input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftpLK4ZZitKw"
      },
      "outputs": [],
      "source": [
        "eigvals, eigvecs = torch.linalg.eigh(B_proj)\n",
        "\n",
        "sims = einops.einsum(eigvecs, mlp_inputs.cpu().detach(), \"digit h eig, b h -> digit eig b\")\n",
        "acts = eigvals.unsqueeze(-1) * (sims)**2\n",
        "\n",
        "sims_noisy = einops.einsum(eigvecs, mlp_inputs_noisy.cpu().detach(), \"digit h eig, b h -> digit eig b\")\n",
        "acts_noisy = eigvals.unsqueeze(-1) * (sims)**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "jbzP5GmOjYvH",
        "outputId": "c09b0615-023f-4490-983c-62b9d5bf4776"
      },
      "outputs": [],
      "source": [
        "cls_idx = 4\n",
        "eig_idx = -1\n",
        "\n",
        "plt.hist(sims[cls_idx,eig_idx],100, alpha=0.5, density=True);\n",
        "plt.hist(sims_noisy[cls_idx,eig_idx],100, alpha=0.5, density=True);\n",
        "\n",
        "plt.xlabel('Activation')\n",
        "plt.ylabel('Count')\n",
        "plt.yscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQX3pIy6v7ND"
      },
      "source": [
        "## Mean Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNL2HnL6QlGs"
      },
      "outputs": [],
      "source": [
        "eigvals_list = []\n",
        "eigvecs_list = []\n",
        "for digit in range(10):\n",
        "    with torch.no_grad():\n",
        "        Q = B_proj[digit].reshape(model.cfg.d_hidden, model.cfg.d_hidden)\n",
        "        eigvals, eigvecs = torch.linalg.eigh(Q)\n",
        "    eigvals_list.append(eigvals)\n",
        "    eigvecs_list.append(eigvecs)\n",
        "eigvals = torch.stack(eigvals_list, dim=0)\n",
        "eigvecs = torch.stack(eigvecs_list, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0PP7RDBRAPS"
      },
      "outputs": [],
      "source": [
        "img_size = (28,28)\n",
        "freq_thresh = 0.01\n",
        "\n",
        "acts_list = []\n",
        "avg_img = torch.zeros(img_size[0]*img_size[1])\n",
        "count = 0\n",
        "for images, labels in train_loader:\n",
        "    images = images.reshape(-1, img_size[0]*img_size[1])\n",
        "    acts = eigvals * (einops.einsum(eigvecs, W_in, images, \"digit h eig, h pix, b pix  -> b digit eig\"))**2\n",
        "    acts_list.append(acts)\n",
        "    avg_img += images.mean(dim=0)\n",
        "    count += acts.shape[0]\n",
        "\n",
        "avg_img /= count\n",
        "acts = torch.cat(acts_list, dim=0)\n",
        "mean_acts = acts.mean(dim=0)\n",
        "freqs = (acts > freq_thresh).float().mean(dim=0)\n",
        "\n",
        "large_acts = acts.clone()\n",
        "large_acts[large_acts <= freq_thresh] = 0\n",
        "mean_large_acts = large_acts.sum(dim=0) / (large_acts > 0).sum(dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "fnWWyTBLgMQ8",
        "outputId": "6c1b14a2-2ed2-458c-d71c-a792cc38b10d"
      },
      "outputs": [],
      "source": [
        "digits = [0,1,2,3]\n",
        "num = 30\n",
        "\n",
        "plt.figure(figsize=(10,3),dpi=150, layout='compressed')\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "for digit in digits:\n",
        "    x = eigvals[digit].sort(descending=True).values\n",
        "    plt.plot(x[:num], '.-', label=f\"{digit}\")\n",
        "plt.title(f'Eigenvalues')\n",
        "plt.legend(title='Digit')\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Value')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "for digit in digits:\n",
        "    x = freqs[digit].sort(descending=True).values\n",
        "    plt.plot(x[:num], '.-', label=f\"{digit}\")\n",
        "# plt.legend(title='Digit')\n",
        "plt.title(f'Frequencies (>{freq_thresh})')\n",
        "plt.xlabel('Rank')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "for digit in digits:\n",
        "    x = mean_acts[digit].sort(descending=True).values\n",
        "    plt.plot(x[:num], '.-', label=f\"{digit}\")\n",
        "# plt.legend(title='Digit')\n",
        "plt.title(f'Mean Activation')\n",
        "plt.xlabel('Rank')\n",
        "plt.xlim([-1,num+1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eyA_Wteu5Mu"
      },
      "source": [
        "## Performance Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhL8192f2DtW",
        "outputId": "36a17f3e-9bbc-4b78-fb83-bcec8a4f18da"
      },
      "outputs": [],
      "source": [
        "W = model.layers[0].linear1.weight.to(\"cpu\").detach()\n",
        "V = model.layers[0].linear2.weight.to(\"cpu\").detach()\n",
        "W_out = model.linear_out.weight.to(\"cpu\").detach()\n",
        "W_in = model.linear_in.weight.to(\"cpu\").detach()\n",
        "\n",
        "B = get_B_tensor(W, V)\n",
        "B = einops.rearrange(B, \"out (in1 in2) -> out in1 in2\", in1 = model.cfg.d_hidden)\n",
        "B_proj = einops.einsum(W_out, B, \"class h2, h2 in1 in2-> class in1 in2\")\n",
        "\n",
        "eigvals, eigvecs = torch.linalg.eigh(B_proj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysD2Xxnz3P91"
      },
      "outputs": [],
      "source": [
        "class SingleLayerTopEigsModel(torch.nn.Module):\n",
        "    def __init__(self, eigvecs, eigvals, W_in):\n",
        "        super().__init__()\n",
        "        self.eigvecs = eigvecs\n",
        "        self.eigvals = eigvals\n",
        "        self.W_in = W_in\n",
        "\n",
        "    def set_activations(self):\n",
        "        images = train_dataset.data.reshape(-1, 28*28)/255 #convert uint8 to float\n",
        "        sims = einops.einsum(images, self.W_in, self.eigvecs, \"b pix, h pix, class h eig -> b class eig\")\n",
        "        self.acts = (self.eigvals.unsqueeze(0) * (sims)**2).mean(dim=0)\n",
        "\n",
        "    def get_eigvecs(self, topk = None, topk_method = 'paired'):\n",
        "        if topk is None:\n",
        "            return self.eigvecs, self.eigvals\n",
        "\n",
        "        if topk_method == 'paired':\n",
        "            #take topk positive and topk negative eigenvectors\n",
        "            eigvecs = torch.cat([self.eigvecs[:, :, :topk], self.eigvecs[:, :, -topk:]], dim=-1)\n",
        "            eigvals = torch.cat([self.eigvals[:, :topk], self.eigvals[:, -topk:]], dim=-1)\n",
        "        elif topk_method == 'max_eigs':\n",
        "            idxs = self.eigvals.abs().sort(descending=True, dim=-1).indices\n",
        "            eigvals = torch.stack([self.eigvals[i,idxs[i,:topk]] for i in range(self.eigvals.shape[0])], dim=0)\n",
        "            eigvecs = torch.stack([self.eigvecs[i, :, idxs[i,:topk]] for i in range(self.eigvecs.shape[0])], dim=0)\n",
        "        elif topk_method == 'max_act':\n",
        "            idxs = self.acts.abs().sort(descending=True, dim=-1).indices\n",
        "            eigvals = torch.stack([self.eigvals[i,idxs[i,:topk]] for i in range(self.eigvals.shape[0])], dim=0)\n",
        "            eigvecs = torch.stack([self.eigvecs[i, :, idxs[i,:topk]] for i in range(self.eigvecs.shape[0])], dim=0)\n",
        "        return eigvecs, eigvals\n",
        "\n",
        "    def forward(self, x, topk = None, topk_method = 'paired'):\n",
        "        x = x @ self.W_in.T\n",
        "\n",
        "        eigvecs, eigvals = self.get_eigvecs(topk = topk, topk_method = topk_method)\n",
        "        sims = einops.einsum(eigvecs, x, \"class h eig, b h -> b class eig\")\n",
        "        acts = eigvals.unsqueeze(0) * (sims)**2\n",
        "        logits = acts.sum(dim=-1)\n",
        "        return logits\n",
        "\n",
        "    def criterion(self, output, labels):\n",
        "        return nn.CrossEntropyLoss()(output, labels)\n",
        "\n",
        "    def validation_accuracy(self, test_loader, topk = None, topk_method = 'paired', print_acc=True):\n",
        "        # In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "        with torch.no_grad():\n",
        "            n_correct = 0\n",
        "            n_samples = 0\n",
        "            loss_sum = 0\n",
        "            count = 0\n",
        "            if topk_method == 'max_act':\n",
        "                self.set_activations()\n",
        "            for images, labels in test_loader:\n",
        "                images = images.reshape(-1, 28*28)\n",
        "                labels = labels\n",
        "                outputs = self.forward(images, topk = topk, topk_method = topk_method)\n",
        "                # max returns (value ,index)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                n_samples += labels.size(0)\n",
        "                n_correct += (predicted == labels).sum().item()\n",
        "                loss_sum += self.criterion(outputs, labels).item()\n",
        "                count += 1\n",
        "\n",
        "            acc = 100.0 * n_correct / n_samples\n",
        "            loss = loss_sum / count\n",
        "            if print_acc:\n",
        "              print(f'Accuracy on validation set: {acc} %')\n",
        "        return acc, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcEk7wB6Cqk-"
      },
      "outputs": [],
      "source": [
        "eig_model = SingleLayerTopEigsModel(eigvecs, eigvals, W_in)\n",
        "\n",
        "topks = np.arange(1,40)\n",
        "accs = []\n",
        "losses = []\n",
        "for k in topks:\n",
        "    acc, loss = eig_model.validation_accuracy(test_loader, topk = k, topk_method='max_act', print_acc=False)\n",
        "    accs.append(acc)\n",
        "    losses.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "YAdB385xfmRt",
        "outputId": "1437396f-fa65-415f-939c-2d2a55ccc56f"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(4,3), dpi=150)\n",
        "ax1.plot(2*topks, accs, '.-', color='C0')\n",
        "ax1.set_xlabel('Top eigenvectors per digit')\n",
        "ax1.set_ylabel('Accuracy', color='C0')\n",
        "ax1.set_xticks([0,5, 10,15,20,25,30], [0,5,10,15,20,25,30])\n",
        "ax1.tick_params(axis='y', labelcolor='C0')\n",
        "ax1.set_title('Truncated Model')\n",
        "ax1.set_xlim(0,31)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "accs = np.array(accs)\n",
        "base_acc, base_loss =  eig_model.validation_accuracy(test_loader, print_acc=False)\n",
        "acc_drop = (base_acc - accs) / base_acc\n",
        "\n",
        "ax2.plot(2*topks, 100 * acc_drop, '.-', color='C1')\n",
        "ax2.set_yscale('log')\n",
        "ax2.set_ylabel('Drop in Accuracy (%)', color='C1', rotation=270)\n",
        "ax2.tick_params(axis='y', labelcolor='C1')\n",
        "ax2.set_yticks([0.01, 0.1, 1, 10, 100], ['0.01%', '0.1%', '1%', '10%', '100%'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "9HHwsWLg2PR6",
        "outputId": "15486637-1ce6-44a4-8154-9d6486ad5623"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(4,3), dpi=150)\n",
        "ax1.plot(topks, accs, '.-', color='C0')\n",
        "ax1.set_xlabel('Top eigenvectors per digit')\n",
        "ax1.set_ylabel('Accuracy', color='C0')\n",
        "ax1.set_xticks([0,5, 10,15,20,25,30], [0,5,10,15,20,25,30])\n",
        "ax1.tick_params(axis='y', labelcolor='C0')\n",
        "ax1.set_title('Truncated Model')\n",
        "ax1.set_xlim(0,31)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "accs = np.array(accs)\n",
        "base_acc, base_loss =  eig_model.validation_accuracy(test_loader, print_acc=False)\n",
        "acc_drop = (base_acc - accs) / base_acc\n",
        "\n",
        "ax2.plot( topks, 100 * acc_drop, '.-', color='C1')\n",
        "ax2.set_yscale('log')\n",
        "ax2.set_ylabel('Drop in Accuracy (%)', color='C1', rotation=270)\n",
        "ax2.tick_params(axis='y', labelcolor='C1')\n",
        "ax2.set_yticks([0.01, 0.1, 1, 10, 100], ['0.01%', '0.1%', '1%', '10%', '100%'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "AMhLNW9GicP4",
        "outputId": "124e46e0-aca7-4ad0-d569-e7202d364b5a"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(4,3), dpi=150)\n",
        "ax1.plot(topks, accs, '.-', color='C0')\n",
        "ax1.set_xlabel('Top eigenvectors per digit')\n",
        "ax1.set_ylabel('Accuracy', color='C0')\n",
        "ax1.set_xticks([0,5, 10,15,20,25,30], [0,5,10,15,20,25,30])\n",
        "ax1.tick_params(axis='y', labelcolor='C0')\n",
        "ax1.set_title('Truncated Model')\n",
        "ax1.set_xlim(0,31)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "accs = np.array(accs)\n",
        "base_acc, base_loss =  eig_model.validation_accuracy(test_loader, print_acc=False)\n",
        "acc_drop = (base_acc - accs) / base_acc\n",
        "\n",
        "ax2.plot( topks, 100 * acc_drop, '.-', color='C1')\n",
        "ax2.set_yscale('log')\n",
        "ax2.set_ylabel('Drop in Accuracy (%)', color='C1', rotation=270)\n",
        "ax2.tick_params(axis='y', labelcolor='C1')\n",
        "ax2.set_yticks([0.01, 0.1, 1, 10, 100], ['0.01%', '0.1%', '1%', '10%', '100%'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRR9MmeiY890"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnzkUMOEyHdV"
      },
      "source": [
        "## Sparsified model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uAuXs7Ryj2s"
      },
      "outputs": [],
      "source": [
        "class SparseModelConfig:\n",
        "    def __init__(self):\n",
        "        self.random_seed = 0\n",
        "\n",
        "        self.l1_param = 0.1\n",
        "\n",
        "        self.lr = 0.001\n",
        "        self.lr_decay = 0.5\n",
        "        self.lr_decay_step = 2\n",
        "\n",
        "class SingleLayerSparseModel(torch.nn.Module):\n",
        "    def __init__(self, cfg, eigvecs, eigvals, W_in):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.eigvecs = torch.nn.Parameter(eigvecs, requires_grad=False)  # (cls, h, eig)\n",
        "        self.eigvals = torch.nn.Parameter(eigvals, requires_grad=False) # (class, eig)\n",
        "        self.W_in = torch.nn.Parameter(W_in, requires_grad=False)\n",
        "\n",
        "        self.bias = torch.nn.Parameter(torch.zeros(eigvecs.shape[0], eigvecs.shape[2]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.cfg.device)\n",
        "        x = x @ self.W_in.T\n",
        "\n",
        "        sims = einops.einsum(self.eigvecs, x, \"class h eig, b h -> b class eig\")\n",
        "        acts = torch.nn.functional.relu((sims)**2 + self.bias)\n",
        "        acts_out = self.eigvals.unsqueeze(0) * acts\n",
        "        logits = acts_out.sum(dim=-1)\n",
        "        return logits, acts\n",
        "\n",
        "    def criterion(self, output, labels):\n",
        "        return nn.CrossEntropyLoss()(output, labels)\n",
        "\n",
        "    def validation_accuracy(self, test_loader, print_acc=True):\n",
        "        # In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "        with torch.no_grad():\n",
        "            n_correct = 0\n",
        "            n_samples = 0\n",
        "            loss_sum = 0\n",
        "            count = 0\n",
        "            for images, labels in test_loader:\n",
        "                images = images.reshape(-1, 28*28).to(self.cfg.device)\n",
        "                labels = labels.to(self.cfg.device)\n",
        "                outputs, _ = self.forward(images)\n",
        "                # max returns (value ,index)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                n_samples += labels.size(0)\n",
        "                n_correct += (predicted == labels).sum().item()\n",
        "                loss_sum += self.criterion(outputs, labels).item()\n",
        "                count += 1\n",
        "\n",
        "            acc = 100.0 * n_correct / n_samples\n",
        "            loss = loss_sum / count\n",
        "            if print_acc:\n",
        "              print(f'Accuracy on validation set: {acc} %, Loss: {loss:.4f}')\n",
        "        return acc, loss\n",
        "\n",
        "    def train(self, train_loader, test_loader, optimizer=None, scheduler=None):\n",
        "        if optimizer is None:\n",
        "            optimizer = torch.optim.AdamW(self.parameters(), lr=self.cfg.lr, weight_decay=self.cfg.weight_decay)\n",
        "\n",
        "        num_epochs = self.cfg.num_epochs\n",
        "        n_total_steps = len(train_loader)\n",
        "        for epoch in range(num_epochs):\n",
        "            _ = self.validation_accuracy(test_loader)\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "                # origin shape: [100, 1, 28, 28]\n",
        "                # resized: [100, 784]\n",
        "                images = images.reshape(-1, 28*28).to(self.cfg.device)\n",
        "                labels = labels.to(self.cfg.device)\n",
        "\n",
        "                # Forward pass\n",
        "                logits, acts = self.forward(images)\n",
        "                L1 = einops.rearrange(acts.abs(), \"b class eig -> b (class eig)\").mean().mean()\n",
        "                L0 =  einops.einsum((acts > 0).float(), \"b class eig -> b\").mean()\n",
        "                loss = self.criterion(logits, labels)\n",
        "                loss_opt = loss + self.cfg.l1_param * L1\n",
        "\n",
        "                # Backward and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss_opt.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                if (i+1) % 100 == 0:\n",
        "                    print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}, L1: {L1.item(): .4f}, L0: {L0.item(): .4f}')\n",
        "\n",
        "            if (scheduler is not None):\n",
        "                scheduler.step()\n",
        "                print(f'learning rate = {scheduler.get_last_lr()[0]}')\n",
        "        _ = self.validation_accuracy(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHZz_2Ts4tYE"
      },
      "outputs": [],
      "source": [
        "eigvals, eigvecs = torch.linalg.eigh(B_proj)\n",
        "W_in = model.linear_in.weight.cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "yxk4iOx74Sui",
        "outputId": "86fe0d68-3c23-4868-a3d9-05d7d209f6cd"
      },
      "outputs": [],
      "source": [
        "cfg = SparseModelConfig()\n",
        "cfg.device = \"cuda\"\n",
        "cfg.lr_param = 10\n",
        "\n",
        "cfg.num_epochs = 50\n",
        "cfg.lr = 0.05\n",
        "cfg.lr_decay = 0.5\n",
        "cfg.lr_decay_step = 2\n",
        "\n",
        "sparse_model = SingleLayerSparseModel(cfg, eigvecs, eigvals, W_in).to(cfg.device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(sparse_model.parameters(), lr=cfg.lr)\n",
        "# linearLR = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1, total_iters = 2)\n",
        "# stepLR = torch.optim.lr_scheduler.StepLR(optimizer, step_size=cfg.lr_decay_step, gamma=cfg.lr_decay)\n",
        "# constLR = torch.optim.lr_scheduler.ConstantLR(optimizer, factor = cfg.lr_decay**(10/cfg.lr_decay_step), total_iters = 1000)\n",
        "# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[linearLR, stepLR, constLR], milestones=[2, 13])\n",
        "\n",
        "sparse_model.train(train_loader, test_loader, optimizer = optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCfHGBg74--g"
      },
      "outputs": [],
      "source": [
        "dataset = train_dataset\n",
        "img_size = (28,28)\n",
        "images = dataset.data.reshape(-1, img_size[0]*img_size[1])/255\n",
        "images = images.to(sparse_model.cfg.device)\n",
        "\n",
        "logits, acts = sparse_model.forward(images)\n",
        "acts = acts.cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADWM31VS9hPm",
        "outputId": "9ffa0c1f-35e4-4195-a715-e5090a30f3a1"
      },
      "outputs": [],
      "source": [
        "acts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "qmzMwIRACaMM",
        "outputId": "82db503b-e2a1-4c40-8b62-2dc01d9a33db"
      },
      "outputs": [],
      "source": [
        "cls_idx = 2\n",
        "eig_idx = -10\n",
        "\n",
        "plt.hist(acts[:, cls_idx, eig_idx], 100)\n",
        "plt.yscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "MKuG97n9Cwh-",
        "outputId": "edc9c388-34a9-40fd-b8da-2477112991c7"
      },
      "outputs": [],
      "source": [
        "act_freqs = (acts > 0).float().mean(dim=0)\n",
        "\n",
        "cls_idx = 0\n",
        "\n",
        "plt.plot(act_freqs[cls_idx],'.-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKfQdR7eyJwM"
      },
      "outputs": [],
      "source": [
        "dataset = train_dataset\n",
        "img_size = (28,28)\n",
        "images = dataset.data.reshape(-1, img_size[0]*img_size[1])/255\n",
        "images = images.cuda()\n",
        "\n",
        "noise = model.cfg.noise_dense * torch.randn_like(images)\n",
        "_ = model.forward(images.mean(dim=0, keepdim=True) + noise, inference=False)\n",
        "mlp_inputs_noisy = model.layers[0].input\n",
        "\n",
        "_ = model.forward(images, inference=True)\n",
        "mlp_inputs = model.layers[0].input\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0psPGRJWyJwM"
      },
      "outputs": [],
      "source": [
        "eigvals, eigvecs = torch.linalg.eigh(B_proj)\n",
        "\n",
        "sims = einops.einsum(eigvecs, mlp_inputs.cpu().detach(), \"digit h eig, b h -> digit eig b\")\n",
        "acts = eigvals.unsqueeze(-1) * (sims)**2\n",
        "\n",
        "sims_noisy = einops.einsum(eigvecs, mlp_inputs_noisy.cpu().detach(), \"digit h eig, b h -> digit eig b\")\n",
        "acts_noisy = eigvals.unsqueeze(-1) * (sims)**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj5DkBbHy3yr"
      },
      "source": [
        "# Eigen-decomposition Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn-i7k57zTcJ",
        "outputId": "a867f858-6024-406f-b102-717a9aa14036"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XlfWB5cMhB7"
      },
      "outputs": [],
      "source": [
        "filename_base = '/content/drive/MyDrive/AI Safety/Bilinear Features/Reproducibility Data/eigendecomp_20240520_v2'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50xTeVROnMLg"
      },
      "source": [
        "## Train and save replicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v49neJC_y3mM"
      },
      "outputs": [],
      "source": [
        "cfg = MnistConfig()\n",
        "cfg.random_seed = 0\n",
        "cfg.n_layers = 1\n",
        "cfg.d_hidden = 300\n",
        "cfg.num_epochs = 2 + 10 + 40\n",
        "cfg.lr = 0.001\n",
        "cfg.lr_decay = 0.5\n",
        "cfg.lr_decay_step = 2\n",
        "cfg.weight_decay = 0.5\n",
        "cfg.rms_norm = False\n",
        "cfg.bias = False\n",
        "cfg.noise_sparse = 0\n",
        "cfg.noise_dense = 0.33\n",
        "cfg.layer_noise = 0.33\n",
        "\n",
        "cfgs = []\n",
        "hidden_dims = [30, 50, 100, 300, 500, 1000]\n",
        "for hidden_dim in hidden_dims:\n",
        "    replicates = 5\n",
        "    for i in range(replicates):\n",
        "        cfg.random_seed = i\n",
        "        cfg.d_hidden = hidden_dim\n",
        "        cfg.filename = filename_base + f'_h{hidden_dim}_rep{i}.pt'\n",
        "        cfgs.append(copy.deepcopy(cfg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18BLq8s_p5Dh"
      },
      "outputs": [],
      "source": [
        "def save_model_data(model, filename):\n",
        "    accuracy, loss = model.validation_accuracy(test_loader)\n",
        "\n",
        "    W = model.layers[0].linear1.weight.to(\"cpu\").detach()\n",
        "    V = model.layers[0].linear2.weight.to(\"cpu\").detach()\n",
        "    W_out = model.linear_out.weight.to(\"cpu\").detach()\n",
        "    W_in = model.linear_in.weight.to(\"cpu\").detach()\n",
        "    B = einops.einsum(W_out, W, V, \"class h, h in1, h in2 -> class in1 in2\")\n",
        "    B_proj = 0.5 * B + 0.5 * B.transpose(-2,-1)\n",
        "\n",
        "    eigvals, eigvecs = torch.linalg.eigh(B_proj)\n",
        "\n",
        "    with open(filename, 'wb') as f:\n",
        "        data = {'cfg':cfg, 'eigvals':eigvals, 'eigvecs':eigvecs, 'W_in': W_in,\n",
        "                'accuracy':accuracy, 'loss':loss}\n",
        "        torch.save(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KJIQ8WfKi3Q",
        "outputId": "7bda56b7-4b77-4a8c-e03a-fe786e93052e"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n",
        "for i, cfg in enumerate(cfgs):\n",
        "    model = MnistModel(cfg).to(\"cuda\")\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    linearLR = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1, total_iters = 2)\n",
        "    stepLR = torch.optim.lr_scheduler.StepLR(optimizer, step_size=cfg.lr_decay_step, gamma=cfg.lr_decay)\n",
        "    constLR = torch.optim.lr_scheduler.ConstantLR(optimizer, factor = cfg.lr_decay**(10/cfg.lr_decay_step), total_iters = 1000)\n",
        "    scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[linearLR, stepLR, constLR], milestones=[2, 13])\n",
        "\n",
        "    model.train(train_loader, test_loader, optimizer = optimizer, scheduler = scheduler)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model = model.to(device)\n",
        "        model.cfg.device = device\n",
        "        save_model_data(model, model.cfg.filename)\n",
        "        print(f'Saved {model.cfg.filename}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc8QoPRlBGkF"
      },
      "source": [
        "## Across initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk_Oy6iRBXkM"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 300\n",
        "replicates = 20\n",
        "\n",
        "eigvals_list = []\n",
        "eigvecs_list = []\n",
        "W_in_list = []\n",
        "for i in range(replicates):\n",
        "    filename = filename_base + f'_h{hidden_dim}_rep{i}.pt'\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = torch.load(f)\n",
        "        cfg = data['cfg']\n",
        "        eigvals_list.append(data['eigvals'])\n",
        "        eigvecs_list.append(data['eigvecs'])\n",
        "        W_in_list.append(data['W_in'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtzCIyMuCWcJ"
      },
      "outputs": [],
      "source": [
        "max_sims = []\n",
        "for i in range(replicates):\n",
        "    for j in range(replicates):\n",
        "        if i == j:\n",
        "            continue\n",
        "\n",
        "        eigvecs0 = einops.einsum(eigvecs_list[i], W_in_list[i], \"class h eig, h pix -> class eig pix\")\n",
        "        eigvecs1 = einops.einsum(eigvecs_list[j], W_in_list[j], \"class h eig, h pix -> class eig pix\")\n",
        "\n",
        "        eigvecs0 = eigvecs0 / eigvecs0.norm(dim=-1, keepdim=True)\n",
        "        eigvecs1 = eigvecs1 / eigvecs1.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        sims = einops.einsum(eigvecs0, eigvecs1,\n",
        "                            \"class eig1 pix, class eig2 pix  -> class eig1 eig2\")\n",
        "        max_sim = sims.abs().max(dim=-1).values\n",
        "        max_sims.append(max_sim)\n",
        "max_sims = torch.stack(max_sims)\n",
        "max_sims_flat = max_sims.reshape(-1, max_sims.shape[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "WwUEIGzHG7AU",
        "outputId": "80ec0ed0-0b9d-4686-9d0e-72a839dc522e"
      },
      "outputs": [],
      "source": [
        "# x = torch.arange(svd_components)\n",
        "pos = max_sims_flat[:,-20:].mean(dim=0).flip(0)\n",
        "neg = max_sims_flat[:,:20].mean(dim=0)\n",
        "\n",
        "plt.figure(figsize=(4,3))\n",
        "plt.plot(pos,'o-', markersize=5, label='Positive')\n",
        "plt.plot(neg,'o-', markersize=5,zorder=-1, label='Negative')\n",
        "plt.legend()\n",
        "plt.title('Across Initializations')\n",
        "plt.xlabel('Eigenvector Rank')\n",
        "plt.ylabel('Cosine Similarity')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0nXrm9TSPQH"
      },
      "source": [
        "## Across Hidden Dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3YODnewSVFD"
      },
      "outputs": [],
      "source": [
        "hidden_dims = [30, 50, 100, 300, 500, 1000]\n",
        "replicates = 5\n",
        "\n",
        "eigvals_dict = {}\n",
        "eigvecs_dict = {}\n",
        "W_in_dict = {}\n",
        "for hidden_dim in hidden_dims:\n",
        "    for i in range(replicates):\n",
        "        filename = filename_base + f'_h{hidden_dim}_rep{i}.pt'\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = torch.load(f)\n",
        "            cfg = data['cfg']\n",
        "            eigvals_dict[(hidden_dim, i)]= data['eigvals']\n",
        "            eigvecs_dict[(hidden_dim, i)]= data['eigvecs']\n",
        "            W_in_dict[(hidden_dim, i)]= data['W_in']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bczq8gPSVFE",
        "outputId": "34e1163b-38de-40cf-fd59-517a616be336"
      },
      "outputs": [],
      "source": [
        "max_sims_list = []\n",
        "\n",
        "hidden1 = 300\n",
        "for hidden2 in hidden_dims:\n",
        "    max_sims = []\n",
        "    for i in range(replicates):\n",
        "        for j in range(replicates):\n",
        "            if hidden1 == hidden2 and i == j:\n",
        "                continue\n",
        "\n",
        "            eigvecs0 = einops.einsum(eigvecs_dict[(hidden1,i)], W_in_dict[(hidden1,i)], \"class h eig, h pix -> class eig pix\")\n",
        "            eigvecs1 = einops.einsum(eigvecs_dict[(hidden2,j)], W_in_dict[(hidden2,j)], \"class h eig, h pix -> class eig pix\")\n",
        "\n",
        "            eigvecs0 = eigvecs0 / eigvecs0.norm(dim=-1, keepdim=True)\n",
        "            eigvecs1 = eigvecs1 / eigvecs1.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            sims = einops.einsum(eigvecs0, eigvecs1,\n",
        "                                \"class eig1 pix, class eig2 pix  -> class eig1 eig2\")\n",
        "            max_sim = sims.abs().max(dim=-1).values\n",
        "            max_sims.append(max_sim)\n",
        "    max_sims = torch.stack(max_sims)\n",
        "    max_sims = max_sims.reshape(-1, max_sims.shape[-1])\n",
        "    max_sims_list.append(max_sims.mean(dim=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "tS6_HqyASVFE",
        "outputId": "e463325a-a364-4025-8a62-fb469ceabf92"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4,3))\n",
        "\n",
        "ranks = [0, 2, 5, 10, 15]\n",
        "hiddens = np.array(hidden_dims)\n",
        "\n",
        "sims = []\n",
        "for i, hidden in enumerate(hiddens):\n",
        "    positives = max_sims_list[i].flip(0)[ranks]\n",
        "    sims.append(positives)\n",
        "sims = torch.stack(sims)\n",
        "\n",
        "for i in range(len(ranks)):\n",
        "    plt.plot(sims[:,i], '.-', label=f'{ranks[i]}')\n",
        "\n",
        "plt.legend(title='Eig. Rank', bbox_to_anchor=(1.01, 1))\n",
        "plt.title('Similarity Across Hidden Dims')\n",
        "plt.xlabel('Hidden Dim')\n",
        "plt.ylabel('Cosine Similarity')\n",
        "plt.xticks(range(len(hiddens)), hiddens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "7r_ZjIXlER_O",
        "outputId": "bf49921f-37e3-4eae-b5a6-c2f8641b39e6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,3.5))\n",
        "\n",
        "for i in range(len(hidden_dims)):\n",
        "    plt.plot(max_sims_list[i][-20:].flip(0), '.-', label=f'{hidden_dims[i]}', markersize=4)\n",
        "\n",
        "plt.legend(title='Hidden Dim', title_fontsize=9, prop={'size':9})\n",
        "plt.title('Similarity Across Hidden Dims')\n",
        "plt.xlabel('Eigenvalue Rank')\n",
        "plt.ylabel('Cosine Similarity')\n",
        "# plt.xticks(range(len(hiddens)), hiddens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xMtHEiJFXzHq",
        "outputId": "3ecc9f54-2dff-4976-ccb7-be0377e45dd5"
      },
      "outputs": [],
      "source": [
        "hidden_ref = 300\n",
        "i = 0\n",
        "eig_idx = -1\n",
        "\n",
        "hiddens = np.array(hidden_dims)\n",
        "\n",
        "\n",
        "for class_idx in range(10):\n",
        "    plt.figure(figsize=(15,4))\n",
        "    for idx, hidden in enumerate(hiddens):\n",
        "\n",
        "        eigvecs0 = einops.einsum(eigvecs_dict[(hidden_ref,i)][class_idx], W_in_dict[(hidden_ref,i)], \"h eig, h pix -> eig pix\")\n",
        "        eigvecs1 = einops.einsum(eigvecs_dict[(hidden,i)][class_idx], W_in_dict[(hidden,i)], \"h eig, h pix -> eig pix\")\n",
        "        sims = einops.einsum(eigvecs0 /eigvecs0.norm(dim=-1, keepdim=True),\n",
        "                            eigvecs1 /eigvecs1.norm(dim=-1, keepdim=True),\n",
        "                            \"eig1 pix, eig2 pix  -> eig1 eig2\")\n",
        "        max_sim = sims.abs().max(dim=-1)\n",
        "\n",
        "        plt.subplot(1,len(hiddens),idx+1)\n",
        "        eig_idx2 = max_sim.indices[eig_idx]\n",
        "        plt.imshow(sims[eig_idx, eig_idx2].sign() * eigvecs1[eig_idx2].reshape(28,28), cmap='RdBu_r', vmin=-0.25, vmax=0.25)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(f'd_hidden={hidden}\\nsim={max_sim.values[eig_idx]:.2f}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfY4KtgiK9eN"
      },
      "source": [
        "# Singular Value Decomposition\n",
        "\n",
        "From the bilinear layer's weight matrices, $W$ and $V$ ( which include the biases as their final column), we can construct the bilinear tensor as\n",
        "\\begin{align}\n",
        "B_{ijk} = \\frac{1}{2}W_{ij} V_{ik} + \\frac{1}{2}V_{ij} W_{ik}\n",
        "\\end{align}\n",
        "Since the $j,k$ indices are both summed over the input, only the symmetric part of $W_{ij}V_{ik}$ contributes, so we've only kept this symmetric part in $B$.\n",
        "\n",
        "We'll take the SVD over the matrix $B_{i(jk)}$ where the input indices $j,k$ are treated as a single index $(jk)$. SVD then results in a decomposition $B_{i(jk)} = R_{is} \\Sigma_{ss'} (Q_{(jk)s'})^T$, where $R$ contains orthogonal output vectors, $S$ is a diagonal matrix of singular values, and $Q$ contains orthongal input vectors.\n",
        "\n",
        "The columns of $Q$ can be treated as a matrix with indices $j,k$. The output for the bilinear layer can then be written as\n",
        "\\begin{align}\n",
        "y_i = \\sum_{jk} B_{ijk}x_jx_k = \\sum_s R_{is} \\sigma_s (x^T Q^s x)\n",
        "\\end{align}\n",
        "\n",
        "It can be difficult to interpret the matrix $Q^s$, so we can go one step further by doing an eigendecomposition. Since $Q^s$ is symmetric, the eigenvalues $\\lambda$ are all real and the eigenvectors $q$ are orthogonal, so $Q^s = \\sum_i \\lambda^s_k (q_k q_k^T)$.  \n",
        "\n",
        "The output in terms of the eigenvectors $q$ is\n",
        "\\begin{align}\n",
        "\\vec{y} = \\sum_{sk} \\ \\vec{r}_s \\ \\sigma_s \\ \\lambda^s_k \\ (q_s^Tx)^2\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FphXGvv3LV_H"
      },
      "outputs": [],
      "source": [
        "W = model.layers[0].linear1.weight.cpu().detach()\n",
        "V = model.layers[0].linear2.weight.cpu().detach()\n",
        "\n",
        "W_out = model.linear_out.weight.to(\"cpu\").detach()\n",
        "W_in = model.linear_in.weight.to(\"cpu\").detach()\n",
        "\n",
        "# svd = compute_symmetric_svd(W, V)\n",
        "B_proj = einops.einsum(W_out, W, V, \"class h, h in1, h in2 -> class in1 in2\")\n",
        "B_proj = 0.5 * B_proj + 0.5 * B_proj.transpose(-2,-1)\n",
        "svd = torch.svd(B_proj.reshape(B_proj.shape[0], -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1OzbkRkTM8F"
      },
      "outputs": [],
      "source": [
        "logits = svd.U\n",
        "B_svd = einops.rearrange(svd.V, \"(in1 in2) comp -> comp in1 in2\", in1 = model.cfg.d_hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djeL2uo-be0u",
        "outputId": "5fd94e65-03d1-4d02-ac34-e8c0b0aa28d7"
      },
      "outputs": [],
      "source": [
        "model.linear_out.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1lgytZdATE2c",
        "outputId": "b23ddb90-1a6e-43f9-cc8c-a427a800ade7"
      },
      "outputs": [],
      "source": [
        "eig_plotter = EigenvectorPlotter(B_svd, logits.T, dataset=train_dataset, Embed = W_in)\n",
        "\n",
        "for i in range(10):\n",
        "    eig_plotter.plot_component(i, suptitle=f\"SVD Comp: {i}\", vmax=0.25,\n",
        "                               classes = range(10), topk_eigs = 3, sort='eigs')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Ix2hdS63DaHI",
        "outputId": "de2d2109-bc30-4c17-c6bb-cb0a3fc8876e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(np.arange(len(svd.S)), svd.S.cpu().detach().numpy(),'.-')\n",
        "# plt.yscale('log')\n",
        "\n",
        "plt.title('Distribution of Singular Values')\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Singular value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnQQFF1-Dtsm"
      },
      "source": [
        "## Performance Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPXUJVyvp1gU"
      },
      "outputs": [],
      "source": [
        "num_pixels = 784\n",
        "input_idxs = get_top_pixel_idxs(train_loader, num_pixels, bias_idx = None)\n",
        "\n",
        "svd_components = 350\n",
        "sing_val_type = 'with R'\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "model.cfg.device = \"cpu\"\n",
        "svds = compute_svds_for_deep_model(model, svd_components, input_idxs, sing_val_type=sing_val_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "eii12aM3ucmT",
        "outputId": "e1027680-a089-4155-c4f3-ecd0a14ccfe0"
      },
      "outputs": [],
      "source": [
        "topK_list = [1] + list(range(2,20,2)) + list(range(20,50,10)) + list(range(50,350,50)) + [350]\n",
        "\n",
        "plot_topk_model_bottleneck(model, svds, topK_list, test_loader,\n",
        "    input_idxs, svd_components, sing_val_type, print_bool = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ZiLi8oaKE7k3",
        "fIy4541d-CVe"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
